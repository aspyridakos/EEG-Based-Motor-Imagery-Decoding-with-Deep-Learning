{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPck7xaPHriXTW1hz2zlSsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aspyridakos/Speechbrain-MOABB-EEG-Processing/blob/main/COMP_432_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EEG-Based Motor Imagery Decoding with Deep Learning"
      ],
      "metadata": {
        "id": "MP0jjL_Bl_lM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "Initial experiment using EEGNET."
      ],
      "metadata": {
        "id": "O9QZLvkImKgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing SpeechBrain-MOABB"
      ],
      "metadata": {
        "id": "g3Tz3invqUe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB\n",
        "!pip install -r extra-requirements.txt # Install additional dependencies"
      ],
      "metadata": {
        "id": "mkUmBKA9gWZ1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install in edit mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "p63mgSwYgycc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define `yaml` file containing the hyper-params for the decoding pipeline using dataset BCNI2014_001 from MOABB."
      ],
      "metadata": {
        "id": "T5AxLbNOjUQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperpyyaml import load_hyperpyyaml, dump_hyperpyyaml\n",
        "\n",
        "exammple_hyperparams = \"\"\"\n",
        "seed: 1234\n",
        "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# DIRECTORIES\n",
        "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
        "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
        "output_folder: !PLACEHOLDER #'path/to/results'\n",
        "\n",
        "# DATASET HPARS\n",
        "# Defining the MOABB dataset.\n",
        "dataset: !new:moabb.datasets.BNCI2014001\n",
        "save_prepared_dataset: True # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards\n",
        "data_iterator_name: !PLACEHOLDER\n",
        "target_subject_idx: !PLACEHOLDER\n",
        "target_session_idx: !PLACEHOLDER\n",
        "events_to_load: null # all events will be loaded\n",
        "original_sample_rate: 250 # Original sampling rate provided by dataset authors\n",
        "sample_rate: 125 # Target sampling rate (Hz)\n",
        "# band-pass filtering cut-off frequencies\n",
        "fmin: 0.13 # @orion_step1: --fmin~\"uniform(0.1, 5, precision=2)\"\n",
        "fmax: 46.0 # @orion_step1: --fmax~\"uniform(20.0, 50.0, precision=3)\"\n",
        "n_classes: 4\n",
        "# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class\n",
        "# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long\n",
        "# dataset interval starts from 2\n",
        "# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)\n",
        "tmin: 0.\n",
        "tmax: 4.0 # @orion_step1: --tmax~\"uniform(1.0, 4.0, precision=2)\"\n",
        "# number of steps used when selecting adjacent channels from a seed channel (default at Cz)\n",
        "n_steps_channel_selection: 2 # @orion_step1: --n_steps_channel_selection~\"uniform(1, 3,discrete=True)\"\n",
        "T: !apply:math.ceil\n",
        "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
        "C: 22\n",
        "# We here specify how to perfom test:\n",
        "# - If test_with: 'last' we perform test with the latest model.\n",
        "# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)\n",
        "# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.\n",
        "# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.\n",
        "test_with: 'last' # 'last' or 'best'\n",
        "test_key: \"acc\" # Possible opts: \"loss\", \"f1\", \"auc\", \"acc\"\n",
        "\n",
        "# METRICS\n",
        "f1: !name:sklearn.metrics.f1_score\n",
        "    average: 'macro'\n",
        "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
        "cm: !name:sklearn.metrics.confusion_matrix\n",
        "metrics:\n",
        "    f1: !ref <f1>\n",
        "    acc: !ref <acc>\n",
        "    cm: !ref <cm>\n",
        "# TRAINING HPARS\n",
        "n_train_examples: 100  # it will be replaced in the train script\n",
        "# checkpoints to average\n",
        "avg_models: 10 # @orion_step1: --avg_models~\"uniform(1, 15,discrete=True)\"\n",
        "number_of_epochs: 862 # @orion_step1: --number_of_epochs~\"uniform(250, 1000, discrete=True)\"\n",
        "lr: 0.0001 # @orion_step1: --lr~\"choices([0.01, 0.005, 0.001, 0.0005, 0.0001])\"\n",
        "# Learning rate scheduling (cyclic learning rate is used here)\n",
        "max_lr: !ref <lr> # Upper bound of the cycle (max value of the lr)\n",
        "base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)\n",
        "step_size_multiplier: 5 #from 2 to 8\n",
        "step_size: !apply:round\n",
        "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
        "    base_lr: !ref <base_lr>\n",
        "    max_lr: !ref <max_lr>\n",
        "    step_size: !ref <step_size>\n",
        "label_smoothing: 0.0\n",
        "loss: !name:speechbrain.nnet.losses.nll_loss\n",
        "    label_smoothing: !ref <label_smoothing>\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter  # epoch counter\n",
        "    limit: !ref <number_of_epochs>\n",
        "batch_size_exponent: 4 # @orion_step1: --batch_size_exponent~\"uniform(4, 6,discrete=True)\"\n",
        "batch_size: !ref 2 ** <batch_size_exponent>\n",
        "valid_ratio: 0.2\n",
        "\n",
        "# DATA AUGMENTATION\n",
        "# cutcat (disabled when min_num_segments=max_num_segments=1)\n",
        "max_num_segments: 3 # @orion_step2: --max_num_segments~\"uniform(2, 6, discrete=True)\"\n",
        "cutcat: !new:speechbrain.augment.time_domain.CutCat\n",
        "    min_num_segments: 2\n",
        "    max_num_segments: !ref <max_num_segments>\n",
        "# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)\n",
        "amp_delta: 0.01742 # @orion_step2: --amp_delta~\"uniform(0.0, 0.5)\"\n",
        "rand_amp: !new:speechbrain.augment.time_domain.RandAmp\n",
        "    amp_low: !ref 1 - <amp_delta>\n",
        "    amp_high: !ref 1 + <amp_delta>\n",
        "# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)\n",
        "shift_delta_: 1 # orion_step2: --shift_delta_~\"uniform(0, 25, discrete=True)\"\n",
        "shift_delta: !ref 1e-2 * <shift_delta_> # 0.250 # 0.-0.25 with steps of 0.01\n",
        "min_shift: !apply:math.floor\n",
        "    - !ref 0 - <sample_rate> * <shift_delta>\n",
        "max_shift: !apply:math.floor\n",
        "    - !ref 0 + <sample_rate> * <shift_delta>\n",
        "time_shift: !new:speechbrain.augment.freq_domain.RandomShift\n",
        "    min_shift: !ref <min_shift>\n",
        "    max_shift: !ref <max_shift>\n",
        "    dim: 1\n",
        "# injection of gaussian white noise\n",
        "snr_white_low: 15.0 # @orion_step2: --snr_white_low~\"uniform(0.0, 15, precision=2)\"\n",
        "snr_white_delta: 19.1 # @orion_step2: --snr_white_delta~\"uniform(5.0, 20.0, precision=3)\"\n",
        "snr_white_high: !ref <snr_white_low> + <snr_white_delta>\n",
        "add_noise_white: !new:speechbrain.augment.time_domain.AddNoise\n",
        "    snr_low: !ref <snr_white_low>\n",
        "    snr_high: !ref <snr_white_high>\n",
        "\n",
        "repeat_augment: 1 # @orion_step1: --repeat_augment 0\n",
        "augment: !new:speechbrain.augment.augmenter.Augmenter\n",
        "    parallel_augment: True\n",
        "    concat_original: True\n",
        "    parallel_augment_fixed_bs: True\n",
        "    repeat_augment: !ref <repeat_augment>\n",
        "    shuffle_augmentations: True\n",
        "    min_augmentations: 4\n",
        "    max_augmentations: 4\n",
        "    augmentations: [\n",
        "        !ref <cutcat>,\n",
        "        !ref <rand_amp>,\n",
        "        !ref <time_shift>,\n",
        "        !ref <add_noise_white>]\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)\n",
        "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
        "    dims: !ref <dims_to_normalize>\n",
        "# MODEL\n",
        "input_shape: [null, !ref <T>, !ref <C>, null]\n",
        "cnn_temporal_kernels: 61 # @orion_step1: --cnn_temporal_kernels~\"uniform(4, 64,discrete=True)\"\n",
        "cnn_temporal_kernelsize: 51 # @orion_step1: --cnn_temporal_kernelsize~\"uniform(24, 62,discrete=True)\"\n",
        "# depth multiplier for the spatial depthwise conv. layer\n",
        "cnn_spatial_depth_multiplier: 4 # @orion_step1: --cnn_spatial_depth_multiplier~\"uniform(1, 4,discrete=True)\"\n",
        "cnn_spatial_max_norm: 1.  # kernel max-norm constaint of the spatial depthwise conv. layer\n",
        "cnn_spatial_pool: 4\n",
        "cnn_septemporal_depth_multiplier: 1  # depth multiplier for the separable temporal conv. layer\n",
        "cnn_septemporal_point_kernels_ratio_: 7 # @orion_step1: --cnn_septemporal_point_kernels_ratio_~\"uniform(0, 8, discrete=True)\"\n",
        "cnn_septemporal_point_kernels_ratio: !ref <cnn_septemporal_point_kernels_ratio_> / 4\n",
        "## number of temporal filters in the separable temporal conv. layer\n",
        "cnn_septemporal_point_kernels_: !ref <cnn_temporal_kernels> * <cnn_spatial_depth_multiplier> * <cnn_septemporal_depth_multiplier>\n",
        "cnn_septemporal_point_kernels: !apply:math.ceil\n",
        "    - !ref <cnn_septemporal_point_kernels_ratio> * <cnn_septemporal_point_kernels_> + 1\n",
        "cnn_septemporal_kernelsize_: 15 # @orion_step1: --cnn_septemporal_kernelsize_~\"uniform(3, 24,discrete=True)\"\n",
        "max_cnn_spatial_pool: 4\n",
        "cnn_septemporal_kernelsize: !apply:round\n",
        "    - !ref <cnn_septemporal_kernelsize_> * <max_cnn_spatial_pool> / <cnn_spatial_pool>\n",
        "cnn_septemporal_pool: 7 # @orion_step1: --cnn_septemporal_pool~\"uniform(1, 8,discrete=True)\"\n",
        "cnn_pool_type: 'avg'\n",
        "dense_max_norm: 0.25  # kernel max-norm constaint of the dense layer\n",
        "dropout: 0.008464 # @orion_step1: --dropout~\"uniform(0.0, 0.5)\"\n",
        "activation_type: 'elu'\n",
        "\n",
        "model: !new:models.EEGNet.EEGNet\n",
        "    input_shape: !ref <input_shape>\n",
        "    cnn_temporal_kernels: !ref <cnn_temporal_kernels>\n",
        "    cnn_temporal_kernelsize: [!ref <cnn_temporal_kernelsize>, 1]\n",
        "    cnn_spatial_depth_multiplier: !ref <cnn_spatial_depth_multiplier>\n",
        "    cnn_spatial_max_norm: !ref <cnn_spatial_max_norm>\n",
        "    cnn_spatial_pool: [!ref <cnn_spatial_pool>, 1]\n",
        "    cnn_septemporal_depth_multiplier: !ref <cnn_septemporal_depth_multiplier>\n",
        "    cnn_septemporal_point_kernels: !ref <cnn_septemporal_point_kernels>\n",
        "    cnn_septemporal_kernelsize: [!ref <cnn_septemporal_kernelsize>, 1]\n",
        "    cnn_septemporal_pool: [!ref <cnn_septemporal_pool>, 1]\n",
        "    cnn_pool_type: !ref <cnn_pool_type>\n",
        "    activation_type: !ref <activation_type>\n",
        "    dense_max_norm: !ref <dense_max_norm>\n",
        "    dropout: !ref <dropout>\n",
        "    dense_n_neurons: !ref <n_classes>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kMRU4cZMhnlh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the `yaml` file on disk"
      ],
      "metadata": {
        "id": "O07Z6NJ4i_h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/example_hyperparams.yaml', 'w')\n",
        "f.write(exammple_hyperparams)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "HyXPtiXViyGX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the neural network on a single cross-validation fold"
      ],
      "metadata": {
        "id": "OoKMBehToPOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "\n",
        "!python train.py /content/example_hyperparams.yaml \\\n",
        "--data_folder '/content/data/BNCI2014001' \\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/single-fold-example/BNCI2014001' \\\n",
        "--data_iterator_name 'leave-one-session-out' \\\n",
        "--target_subject_idx 0 \\\n",
        "--target_session_idx 1 \\\n",
        "--number_of_epochs 50 \\\n",
        "--device 'cpu' # Switch to cuda for a speed up, remove this line to run everything on GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg4Rg6xijRGS",
        "outputId": "114bfa3b-c9f6-4845-b574-7a4574efc7e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/benchmarks/benchmarks/MOABB\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
            "2024-04-02 02:31:24.023146: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-02 02:31:24.023205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-02 02:31:24.025220: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-02 02:31:24.036196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-02 02:31:25.389297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/pipelines/__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
            "  warn(\n",
            "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "Prepare dataset iterators...\n",
            "/content/data/BNCI2014001\n",
            "Choosing from all possible events\n",
            "MNE_DATA is not already configured. It will be set to default location in the home directory - /root/mne_data\n",
            "All datasets will be downloaded to this location, if anything is already downloaded, please move manually to this location\n",
            "/usr/local/lib/python3.10/dist-packages/moabb/datasets/download.py:55: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n",
            "  set_config(key, get_config(\"MNE_DATA\"))\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A01T.mat'.\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n",
            "100%|██████████████████████████████████████| 42.8M/42.8M [00:00<00:00, 237GB/s]\n",
            "SHA256 hash of downloaded file: 054f02e70cf9c4ada1517e9b9864f45407939c1062c6793516585c6f511d0325\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
            "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat' to file '/root/mne_data/MNE-bnci-data/database/data-sets/001-2014/A01E.mat'.\n",
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
            "  warnings.warn(\n",
            "100%|██████████████████████████████████████| 43.8M/43.8M [00:00<00:00, 212GB/s]\n",
            "SHA256 hash of downloaded file: 53d415f39c3d7b0c88b894d7b08d99bcdfe855ede63831d3691af1a45607fb62\n",
            "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
            "Saving the dataset at /content/data/MOABB_pickled/BNCI2014-001/0125_0.13-46.0/sub-001.pkl\n",
            "Session/sessions used as training and validation set: ['0train']\n",
            "Session used as test set: ['1test']\n",
            "Validation indices: [3, 16, 38, 58, 79, 110, 130, 152, 176, 197, 223, 240, 270, 287, 2, 20, 42, 72, 90, 112, 129, 156, 170, 201, 210, 242, 257, 286, 1, 33, 43, 62, 80, 111, 137, 150, 177, 199, 230, 245, 262, 284, 0, 25, 39, 66, 86, 107, 119, 157, 173, 196, 214, 241, 250, 276]\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "Sampling channels: ['Fz', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'C3', 'C1', 'Cz', 'C2', 'C4', 'CP1', 'CPz', 'CP2', 'P1', 'Pz', 'P2']\n",
            "BNCI2014001 has been renamed to BNCI2014_001. BNCI2014001 will be removed in version 1.1.\n",
            "The dataset class name 'BNCI2014001' must be an abbreviation of its code 'BNCI2014-001'. See moabb.datasets.base.is_abbrev for more information.\n",
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Experiment directory: /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test\n",
            "__main__ - Input shape: torch.Size([500, 17, 1])\n",
            "__main__ - Training set avg value: 4.9769884213901605e-08\n",
            "__main__ - Number of examples: 232 (training), 56 (validation), 288 (test)\n",
            "speechbrain.core - Gradscaler enabled: False. Using precision: fp32.\n",
            "speechbrain.core - MOABBBrain Model Statistics:\n",
            "* Total Number of Trainable Parameters: 145.9k\n",
            "* Total Number of Parameters: 145.9k\n",
            "* Trainable Parameters represent 100.0000% of the total size.\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "EEGNet                                   [1, 4]                    --\n",
            "├─Sequential: 1-1                        [1, 17, 1, 428]           --\n",
            "│    └─Conv2d: 2-1                       [1, 500, 17, 61]          --\n",
            "│    │    └─Conv2d: 3-1                  [1, 61, 500, 17]          3,111\n",
            "│    └─BatchNorm2d: 2-2                  [1, 500, 17, 61]          --\n",
            "│    │    └─BatchNorm2d: 3-2             [1, 61, 17, 500]          122\n",
            "│    └─Conv2d: 2-3                       [1, 500, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-3                  [1, 244, 500, 1]          4,148\n",
            "│    └─BatchNorm2d: 2-4                  [1, 500, 1, 244]          --\n",
            "│    │    └─BatchNorm2d: 3-4             [1, 244, 1, 500]          488\n",
            "│    └─ELU: 2-5                          [1, 500, 1, 244]          --\n",
            "│    └─Pooling2d: 2-6                    [1, 125, 1, 244]          --\n",
            "│    │    └─AvgPool2d: 3-5               [1, 244, 125, 1]          --\n",
            "│    └─Dropout: 2-7                      [1, 125, 1, 244]          --\n",
            "│    └─Conv2d: 2-8                       [1, 125, 1, 244]          --\n",
            "│    │    └─Conv2d: 3-6                  [1, 244, 125, 1]          3,660\n",
            "│    └─Conv2d: 2-9                       [1, 125, 1, 428]          --\n",
            "│    │    └─Conv2d: 3-7                  [1, 428, 125, 1]          104,432\n",
            "│    └─BatchNorm2d: 2-10                 [1, 125, 1, 428]          --\n",
            "│    │    └─BatchNorm2d: 3-8             [1, 428, 1, 125]          856\n",
            "│    └─ELU: 2-11                         [1, 125, 1, 428]          --\n",
            "│    └─Pooling2d: 2-12                   [1, 17, 1, 428]           --\n",
            "│    │    └─AvgPool2d: 3-9               [1, 428, 17, 1]           --\n",
            "│    └─Dropout: 2-13                     [1, 17, 1, 428]           --\n",
            "├─Sequential: 1-2                        [1, 4]                    --\n",
            "│    └─Flatten: 2-14                     [1, 7276]                 --\n",
            "│    └─Linear: 2-15                      [1, 4]                    --\n",
            "│    │    └─Linear: 3-10                 [1, 4]                    29,108\n",
            "│    └─LogSoftmax: 2-16                  [1, 4]                    --\n",
            "==========================================================================================\n",
            "Total params: 145,925\n",
            "Trainable params: 145,925\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 42.06\n",
            "==========================================================================================\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 11.35\n",
            "Params size (MB): 0.58\n",
            "Estimated Total Size (MB): 11.97\n",
            "==========================================================================================\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.95e-05 - train loss: 1.39 - valid loss: 1.39, valid f1: 1.63e-01, valid acc: 2.86e-01, valid cm: [[ 0 14  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 13  0  1]\n",
            " [ 0 12  0  2]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 2, lr: 4.03e-05 - train loss: 1.35 - valid loss: 1.39, valid f1: 1.00e-01, valid acc: 2.50e-01, valid cm: [[ 0 14  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 14  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 3, lr: 6.11e-05 - train loss: 1.27 - valid loss: 1.39, valid f1: 2.00e-01, valid acc: 3.04e-01, valid cm: [[ 0 14  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 13  1  0]\n",
            " [ 0 12  0  2]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 4, lr: 8.19e-05 - train loss: 1.19 - valid loss: 1.39, valid f1: 1.35e-01, valid acc: 2.68e-01, valid cm: [[ 0 14  0  0]\n",
            " [ 0 14  0  0]\n",
            " [ 0 13  1  0]\n",
            " [ 0 14  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 5, lr: 9.72e-05 - train loss: 1.09 - valid loss: 1.39, valid f1: 1.94e-01, valid acc: 3.04e-01, valid cm: [[ 5  9  0  0]\n",
            " [ 2 12  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 6  8  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.64e-05 - train loss: 1.01 - valid loss: 1.39, valid f1: 1.99e-01, valid acc: 3.04e-01, valid cm: [[ 6  8  0  0]\n",
            " [ 3 11  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 8  6  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 7\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 7, lr: 5.56e-05 - train loss: 9.35e-01 - valid loss: 1.39, valid f1: 2.13e-01, valid acc: 3.21e-01, valid cm: [[ 7  7  0  0]\n",
            " [ 3 11  0  0]\n",
            " [ 8  6  0  0]\n",
            " [ 9  5  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 8, lr: 3.47e-05 - train loss: 8.65e-01 - valid loss: 1.39, valid f1: 2.13e-01, valid acc: 3.21e-01, valid cm: [[ 7  7  0  0]\n",
            " [ 3 11  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 9  5  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 9, lr: 1.39e-05 - train loss: 8.45e-01 - valid loss: 1.39, valid f1: 2.14e-01, valid acc: 3.21e-01, valid cm: [[ 7  7  0  0]\n",
            " [ 3 11  0  0]\n",
            " [ 8  6  0  0]\n",
            " [10  4  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 10\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 9.7e-06\n",
            "speechbrain.utils.train_logger - epoch: 10, lr: 6.95e-06 - train loss: 8.21e-01 - valid loss: 1.39, valid f1: 2.17e-01, valid acc: 3.21e-01, valid cm: [[ 8  6  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 8  6  0  0]\n",
            " [11  3  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 11\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 3.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 11, lr: 2.78e-05 - train loss: 8.25e-01 - valid loss: 1.39, valid f1: 2.17e-01, valid acc: 3.21e-01, valid cm: [[ 8  6  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 8  6  0  0]\n",
            " [11  3  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n",
            "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 5.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 12, lr: 4.86e-05 - train loss: 8.11e-01 - valid loss: 1.39, valid f1: 2.31e-01, valid acc: 3.39e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 8  6  0  0]\n",
            " [12  2  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 7.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 13, lr: 6.94e-05 - train loss: 7.82e-01 - valid loss: 1.39, valid f1: 2.21e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
            " [ 6  8  0  0]\n",
            " [ 9  5  0  0]\n",
            " [13  1  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 14, lr: 9.03e-05 - train loss: 7.35e-01 - valid loss: 1.39, valid f1: 2.21e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 9  5  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 15, lr: 8.89e-05 - train loss: 6.57e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 16, lr: 6.81e-05 - train loss: 6.10e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 17, lr: 4.72e-05 - train loss: 5.71e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 18, lr: 2.64e-05 - train loss: 5.50e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 2.8e-06\n",
            "speechbrain.utils.train_logger - epoch: 19, lr: 5.56e-06 - train loss: 5.15e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 20, lr: 1.53e-05 - train loss: 5.28e-01 - valid loss: 1.39, valid f1: 2.26e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [11  3  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 21, lr: 3.61e-05 - train loss: 5.12e-01 - valid loss: 1.40, valid f1: 2.23e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [10  4  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 6e-05\n",
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.69e-05 - train loss: 5.08e-01 - valid loss: 1.40, valid f1: 2.21e-01, valid acc: 3.21e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 9  5  0  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 8.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 23, lr: 7.78e-05 - train loss: 5.01e-01 - valid loss: 1.40, valid f1: 2.61e-01, valid acc: 3.39e-01, valid cm: [[11  3  0  0]\n",
            " [ 7  7  0  0]\n",
            " [10  3  1  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n",
            "speechbrain.nnet.schedulers - Changing lr from 0.0001 to 9.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 24, lr: 9.86e-05 - train loss: 4.61e-01 - valid loss: 1.41, valid f1: 2.47e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 9  4  1  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.9e-05 to 7.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 25, lr: 8.06e-05 - train loss: 4.22e-01 - valid loss: 1.41, valid f1: 2.47e-01, valid acc: 3.21e-01, valid cm: [[10  4  0  0]\n",
            " [ 7  7  0  0]\n",
            " [ 9  4  1  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.8e-05 to 5.7e-05\n",
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.97e-05 - train loss: 3.92e-01 - valid loss: 1.42, valid f1: 2.61e-01, valid acc: 3.39e-01, valid cm: [[10  4  0  0]\n",
            " [ 6  8  0  0]\n",
            " [ 9  4  1  0]\n",
            " [14  0  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.8e-05 to 3.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 27, lr: 3.89e-05 - train loss: 3.70e-01 - valid loss: 1.43, valid f1: 2.72e-01, valid acc: 3.57e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 9  4  1  0]\n",
            " [13  1  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.7e-05 to 1.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 28, lr: 1.81e-05 - train loss: 3.61e-01 - valid loss: 1.42, valid f1: 2.72e-01, valid acc: 3.57e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 9  4  1  0]\n",
            " [13  1  0  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-06 to 5.6e-06\n",
            "speechbrain.utils.train_logger - epoch: 29, lr: 2.79e-06 - train loss: 3.64e-01 - valid loss: 1.42, valid f1: 3.01e-01, valid acc: 3.75e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 8  4  2  0]\n",
            " [12  1  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.5e-05 to 2.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 30, lr: 2.36e-05 - train loss: 3.67e-01 - valid loss: 1.42, valid f1: 3.01e-01, valid acc: 3.75e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 8  4  2  0]\n",
            " [12  1  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 31\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.6e-05 to 4.7e-05\n",
            "speechbrain.utils.train_logger - epoch: 31, lr: 4.45e-05 - train loss: 3.47e-01 - valid loss: 1.41, valid f1: 3.28e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 7  4  3  0]\n",
            " [12  1  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 32\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.7e-05 to 6.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 32, lr: 6.53e-05 - train loss: 3.51e-01 - valid loss: 1.40, valid f1: 3.28e-01, valid acc: 3.93e-01, valid cm: [[10  4  0  0]\n",
            " [ 5  9  0  0]\n",
            " [ 7  4  3  0]\n",
            " [12  1  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 33\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.8e-05 to 8.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 33, lr: 8.61e-05 - train loss: 3.30e-01 - valid loss: 1.39, valid f1: 3.39e-01, valid acc: 4.11e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 7  4  3  0]\n",
            " [11  2  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 34\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.2e-05 to 9e-05\n",
            "speechbrain.utils.train_logger - epoch: 34, lr: 9.31e-05 - train loss: 3.22e-01 - valid loss: 1.36, valid f1: 3.26e-01, valid acc: 3.93e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 6  5  3  0]\n",
            " [12  1  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 35\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.1e-05 to 6.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 35, lr: 7.22e-05 - train loss: 3.03e-01 - valid loss: 1.33, valid f1: 3.26e-01, valid acc: 3.93e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 7  4  3  0]\n",
            " [11  2  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 36\n",
            "speechbrain.nnet.schedulers - Changing lr from 5e-05 to 4.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 36, lr: 5.14e-05 - train loss: 2.90e-01 - valid loss: 1.32, valid f1: 3.49e-01, valid acc: 4.11e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 5  5  4  0]\n",
            " [11  2  1  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 37\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.9e-05 to 2.8e-05\n",
            "speechbrain.utils.train_logger - epoch: 37, lr: 3.06e-05 - train loss: 2.81e-01 - valid loss: 1.28, valid f1: 3.66e-01, valid acc: 4.29e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 4  5  5  0]\n",
            " [10  1  3  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 38\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-06 to 7e-06\n",
            "speechbrain.utils.train_logger - epoch: 38, lr: 9.73e-06 - train loss: 2.72e-01 - valid loss: 1.23, valid f1: 3.86e-01, valid acc: 4.46e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 3  5  6  0]\n",
            " [10  1  3  0]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 39\n",
            "speechbrain.nnet.schedulers - Changing lr from 1.3e-05 to 1.4e-05\n",
            "speechbrain.utils.train_logger - epoch: 39, lr: 1.11e-05 - train loss: 2.51e-01 - valid loss: 1.19, valid f1: 4.74e-01, valid acc: 5.00e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 3  4  7  0]\n",
            " [ 8  1  3  2]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 40\n",
            "speechbrain.nnet.schedulers - Changing lr from 3.3e-05 to 3.5e-05\n",
            "speechbrain.utils.train_logger - epoch: 40, lr: 3.20e-05 - train loss: 2.58e-01 - valid loss: 1.13, valid f1: 5.30e-01, valid acc: 5.36e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 3  4  7  0]\n",
            " [ 7  0  3  4]]\n",
            "speechbrain.utils.epoch_loop - Going into epoch 41\n",
            "speechbrain.nnet.schedulers - Changing lr from 5.4e-05 to 5.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 41, lr: 5.28e-05 - train loss: 2.67e-01 - valid loss: 1.09, valid f1: 5.49e-01, valid acc: 5.54e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 3  3  8  0]\n",
            " [ 7  0  3  4]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-48-19+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 42\n",
            "speechbrain.nnet.schedulers - Changing lr from 7.5e-05 to 7.6e-05\n",
            "speechbrain.utils.train_logger - epoch: 42, lr: 7.36e-05 - train loss: 2.52e-01 - valid loss: 1.02, valid f1: 6.11e-01, valid acc: 6.07e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  4  9  0]\n",
            " [ 5  0  3  6]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-48-43+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 43\n",
            "speechbrain.nnet.schedulers - Changing lr from 9.6e-05 to 9.7e-05\n",
            "speechbrain.utils.train_logger - epoch: 43, lr: 9.44e-05 - train loss: 2.42e-01 - valid loss: 9.62e-01, valid f1: 6.32e-01, valid acc: 6.25e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  4  9  0]\n",
            " [ 4  0  3  7]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 44\n",
            "speechbrain.nnet.schedulers - Changing lr from 8.3e-05 to 8.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 44, lr: 8.47e-05 - train loss: 2.29e-01 - valid loss: 8.85e-01, valid f1: 6.47e-01, valid acc: 6.43e-01, valid cm: [[ 9  5  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  3  9  1]\n",
            " [ 2  0  4  8]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-30+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 45\n",
            "speechbrain.nnet.schedulers - Changing lr from 6.3e-05 to 6.1e-05\n",
            "speechbrain.utils.train_logger - epoch: 45, lr: 6.39e-05 - train loss: 2.14e-01 - valid loss: 8.56e-01, valid f1: 6.80e-01, valid acc: 6.79e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  4  9]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-54+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 46\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4e-05\n",
            "speechbrain.utils.train_logger - epoch: 46, lr: 4.31e-05 - train loss: 2.25e-01 - valid loss: 8.31e-01, valid f1: 6.80e-01, valid acc: 6.79e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  4  9]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-50-19+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 47\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 1.9e-05\n",
            "speechbrain.utils.train_logger - epoch: 47, lr: 2.22e-05 - train loss: 2.23e-01 - valid loss: 7.91e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  3 10]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-50-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 48\n",
            "speechbrain.nnet.schedulers - Changing lr from 1e-08 to 1.4e-06\n",
            "speechbrain.utils.train_logger - epoch: 48, lr: 1.40e-06 - train loss: 2.09e-01 - valid loss: 7.71e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  3 10]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-07+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 49\n",
            "speechbrain.nnet.schedulers - Changing lr from 2.1e-05 to 2.2e-05\n",
            "speechbrain.utils.train_logger - epoch: 49, lr: 1.95e-05 - train loss: 2.17e-01 - valid loss: 7.52e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  3 10]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-30+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 50\n",
            "speechbrain.nnet.schedulers - Changing lr from 4.2e-05 to 4.3e-05\n",
            "speechbrain.utils.train_logger - epoch: 50, lr: 4.03e-05 - train loss: 2.18e-01 - valid loss: 7.31e-01, valid f1: 6.99e-01, valid acc: 6.96e-01, valid cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  2  9  2]\n",
            " [ 1  0  3 10]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-54+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-54+00\n",
            "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 8.86e-01, test f1: 6.07e-01, test acc: 6.08e-01, test cm: [[39 27  3  3]\n",
            " [12 60  0  0]\n",
            " [21 12 35  4]\n",
            " [11  6 14 41]]\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-57+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-07+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-50-42+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-54+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-50-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-48-43+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-54+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-48-19+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-30+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-49-06+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from /content/results/single-fold-example/BNCI2014001/leave-one-session-out/sub-001/1test/save/CKPT+2024-04-02+02-51-57+00\n",
            "speechbrain.utils.train_logger - epoch loaded: 50 - test loss: 1.59e-01, test f1: 6.63e-01, test acc: 6.61e-01, test cm: [[10  4  0  0]\n",
            " [ 4 10  0  0]\n",
            " [ 1  3  9  1]\n",
            " [ 2  0  4  8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a complete experiment by looping over the entire dataset."
      ],
      "metadata": {
        "id": "EpO4pCb-piFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./run_experiment.sh --hparams /content/example_hyperparams.yaml \\\n",
        "--data_folder '/content/data/BNCI2014001' \\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output--nsbj 9 --nsess 2 --nruns 1 --train_mode 'leave-one-session-out' \\\n",
        "--number_of_epochs 50 \\\n",
        "--device 'cpu'"
      ],
      "metadata": {
        "id": "jAJqcUITphjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JIioFiVHtLLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/benchmarks/benchmarks/MOABB/\n",
        "\n",
        "!python train.py /content/example_hyperparams.yaml \\\n",
        "--data_folder '/content/data/BNCI2014001' \\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/single-fold-example/BNCI2014001' \\\n",
        "--data_iterator_name 'leave-one-session-out' \\\n",
        "--target_subject_idx 0 \\\n",
        "--target_session_idx 1 \\\n",
        "--number_of_epochs 50"
      ],
      "metadata": {
        "id": "qpYaZ3hFtLhX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}